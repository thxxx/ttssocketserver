{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8d638dc-8c03-4eb2-b80d-cdf6e83ac000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24cb0c3c9ae7447a8c72eb723f1bd49c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/340 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5857c9284b6a409bafe5bcb5d6c21eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c586e8a6f864758bd82de479b59eaea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2605cf540d594769bdb0331224fef72d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocabulary.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "109cd739d69a4e75b863c992a43a6bb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.bin:   0%|          | 0.00/1.62G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "\n",
    "# device: \"cuda\" | \"cpu\" | \"auto\", compute_type: \"float16\" | \"int8_float16\" | \"int8\" | \"fp32\"\n",
    "# 권장: GPU 있으면 \"cuda\"+\"float16\" (최고 속도/정확도 균형)\n",
    "# VRAM이 빠듯하면 \"int8_float16\" (속도↑, 정확도 거의 유지)\n",
    "model = WhisperModel(\n",
    "    \"large-v3-turbo\",                 # turbo 대신 large-v3 원본 가중치도 CT2로 매우 빠름\n",
    "    device=\"cuda\",              # 없으면 \"auto\"\n",
    "    compute_type=\"float16\",     # 또는 \"int8_float16\"\n",
    "    cpu_threads=0,              # CPU용일 때만 의미. 0=자동\n",
    "    num_workers=1               # 디코더 스레드 (GPU에선 크게 의미없음)\n",
    ")\n",
    "\n",
    "# 추론 파라미터\n",
    "params = dict(\n",
    "    beam_size=1,                # 1이면 그리디; 빔서치(>=2)는 느림. 보통 1~2 추천\n",
    "    best_of=1,                  # 그리디일 때는 의미 없음. 작게.\n",
    "    temperature=0.0,            # 안정/속도↑. (불확실 시 fallback으로 [0.0, 0.2, 0.4] 등 가능)\n",
    "    vad_filter=True,            # 무음 제거 → 디코딩량 ↓\n",
    "    vad_parameters=dict(min_silence_duration_ms=500),\n",
    "    chunk_length=15,            # 초 단위. 10~20초 권장(긴 문맥 필요하면 20~30)\n",
    "    no_speech_threshold=0.6,    # 무음 판단 강화로 낭비 줄이기\n",
    "    log_prob_threshold=-1.0,    # 너무 낮으면 실패로 간주하고 temperature fallback 고려\n",
    "    word_timestamps=False,      # 단어 타임스탬프 끄면 속도↑ (필요 시만 True)\n",
    "    condition_on_previous_text=False,  # 청크 간 의존 줄여 속도/안정 ↑\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94072bee-2e7f-4366-842f-abee5c2e6b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.022420644760131836\n",
      "0.14162087440490723\n",
      "ko 5.0\n",
      "[0.00 → 1.46]  이런 얘기들을 되게 많이 하시는데\n",
      "[1.46 → 3.18]  저는 사실 그렇게 생각하지 않았어요\n",
      "[3.18 → 4.98]  당시의 KBT는 매출\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 실행\n",
    "import io\n",
    "import base64\n",
    "from openai import OpenAI\n",
    "import time\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "\n",
    "# base64 문자열 예시\n",
    "with open(\"eo_05.mp3\", \"rb\") as f:\n",
    "    b64_audio = base64.b64encode(f.read()).decode()\n",
    "\n",
    "audio_bytes = base64.b64decode(b64_audio)\n",
    "stt = time.time()\n",
    "data, sr = sf.read(io.BytesIO(audio_bytes), dtype=\"float32\", always_2d=True)\n",
    "mono = data.mean(axis=1)  # 모노 변환\n",
    "mono_16k = librosa.resample(mono, orig_sr=sr, target_sr=16000)\n",
    "print(time.time() - stt)\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "segments, info = model.transcribe(mono_16k, **params)\n",
    "\n",
    "print(time.time() - st)\n",
    "\n",
    "print(info.language, info.duration)\n",
    "for seg in segments:\n",
    "    print(f\"[{seg.start:.2f} → {seg.end:.2f}] {seg.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa6ace1-b545-4f9f-b5cf-c8bb8cd41dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
