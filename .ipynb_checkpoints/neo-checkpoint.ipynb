{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e6b54d9-b01b-4e9b-8701-76450aa3d437",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-08-15 08:17:17 nemo_logging:405] /usr/local/lib/python3.11/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b229d2b365457bbffa5588714701ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "canary-1b-v2.nemo:   0%|          | 0.00/6.36G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-08-15 08:19:14 nemo_logging:393] Tokenizer CanaryBPETokenizer initialized with 16384 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-08-15 08:19:14 nemo_logging:405] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    use_lhotse: true\n",
      "    skip_missing_manifest_entries: true\n",
      "    input_cfg: null\n",
      "    tarred_audio_filepaths: null\n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    shuffle: true\n",
      "    num_workers: 4\n",
      "    pin_memory: true\n",
      "    prompt_format: canary2\n",
      "    max_duration: 40.0\n",
      "    min_duration: 0.01\n",
      "    text_field: answer\n",
      "    lang_field: target_lang\n",
      "    use_bucketing: true\n",
      "    max_tps: null\n",
      "    bucket_duration_bins: null\n",
      "    bucket_batch_size: null\n",
      "    num_buckets: null\n",
      "    bucket_buffer_size: 20000\n",
      "    shuffle_buffer_size: 10000\n",
      "    \n",
      "[NeMo W 2025-08-15 08:19:14 nemo_logging:405] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    use_lhotse: true\n",
      "    prompt_format: canary2\n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 4\n",
      "    shuffle: true\n",
      "    max_duration: 40.0\n",
      "    min_duration: 0.1\n",
      "    num_workers: 2\n",
      "    pin_memory: true\n",
      "    text_field: answer\n",
      "    lang_field: target_lang\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-08-15 08:19:14 nemo_logging:393] PADDING: 0\n",
      "[NeMo I 2025-08-15 08:19:24 nemo_logging:393] Model EncDecMultiTaskModel was successfully restored from /root/.cache/huggingface/hub/models--nvidia--canary-1b-v2/snapshots/7cc2afaad76086004e89254b2de1d4cc7dcdc69f/canary-1b-v2.nemo.\n"
     ]
    }
   ],
   "source": [
    "import nemo.collections.asr as nemo_asr\n",
    "\n",
    "asr_model = nemo_asr.models.ASRModel.from_pretrained(\"nvidia/canary-1b-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9251861-459f-4651-9578-fe5f4a2f421c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-08-15 08:19:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence\n",
      "[NeMo W 2025-08-15 08:19:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Hypothesis(score=0.0, y_sequence=tensor([ 1262, 16122, 16065,  2019,  5682,  1260,  1789, 16122,  1193,  1289,\n",
      "         1207,  1689, 16081, 16067,  1262, 16122, 16065,  1289,  1207,  1689,\n",
      "        16081, 16073,  6922, 16122, 16060,  1289,  1207,  1689, 16081, 16145,\n",
      "         6922, 16122, 16060,  1289,  1207,  1689, 16081, 16145]), text=\"I'm not saying you're the decay, I'm the decay. What's the decay? What's the decay?\", dec_out=None, dec_state=None, timestamp={'word': [], 'segment': [], 'char': []}, alignments=None, frame_confidence=None, token_confidence=None, word_confidence=None, length=0, y=None, lm_state=None, lm_scores=None, ngram_lm_state=None, tokens=None, last_token=None, token_duration=None, last_frame=None)] \n",
      " 0.4983060359954834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "st = time.time()\n",
    "transcriptions = asr_model.transcribe([\"eo_05.mp3\"])\n",
    "print(transcriptions, \"\\n\", time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7afdd3a-0a15-4c3b-8672-b29e43701ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-08-15 08:20:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence\n",
      "[NeMo W 2025-08-15 08:20:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Hypothesis(score=0.0, y_sequence=tensor([ 1305,  3832, 16067,  2259,  1363,  1389, 16136, 16119,  1127,  1123,\n",
      "         1245,  1901,  1240, 16119, 16113,  2936,  1229,  1260, 16073]), text='Hello, this is GPT40 Mini TTS speaking.', dec_out=None, dec_state=None, timestamp={'word': [], 'segment': [], 'char': []}, alignments=None, frame_confidence=None, token_confidence=None, word_confidence=None, length=0, y=None, lm_state=None, lm_scores=None, ngram_lm_state=None, tokens=None, last_token=None, token_duration=None, last_frame=None)] \n",
      " 0.28232884407043457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "\n",
    "transcriptions = asr_model.transcribe([\"output (2).mp3\"])\n",
    "\n",
    "print(transcriptions, \"\\n\", time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349375c0-a71a-4dd6-b0c7-a865ddb0d883",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "model_id = \"openai/gpt-oss-20b\"\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Explain quantum mechanics clearly and concisely.\"},\n",
    "]\n",
    "\n",
    "outputs = pipe(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e67d921-f1f9-48bb-af14-1dd85b8c4450",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
