{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41583911-fbbb-4604-a73f-cef3df232bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"trillionlabs/Tri-1.8B-Translation\",\n",
    "    dtype=\"float16\",               # GPU라면 권장\n",
    "    tensor_parallel_size=1,        # 단일 GPU 보장\n",
    "    enforce_eager=True,            # CUDA graph 캡쳐 이슈 회피\n",
    "    gpu_memory_utilization=0.5,   # 메모리 여유 확보\n",
    "    disable_log_stats=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b618c23d-68ef-4d74-80ba-ea2bd31c61f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = SamplingParams(temperature=0.1, max_tokens=512)\n",
    "\n",
    "target = \"ko\"\n",
    "text = \"\"\"There's so much to do on a day like this, lots of things to do, but maybe later when you're having dinner.\"\"\"\n",
    "\n",
    "prompt_old = f\"\"\"\n",
    "Translate into ko\\n\n",
    "{text}<ko>\n",
    "이런 날에는 할 일이 너무 많고 할 일도 많지만, 나중에 저녁을 먹을 때쯤이면.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Translate into ko\\n\n",
    "There will be a chance to reflect.<ko>\n",
    "\"\"\"\n",
    "out = llm.chat([{\"role\": \"user\", \"content\": prompt}], sampling_params=sp)\n",
    "out[0].outputs[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2004363e-f612-4b01-b993-37aa3a17c527",
   "metadata": {},
   "outputs": [],
   "source": [
    "out[0].outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a137b4-10f7-499f-b0ba-084fb76867d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd8b09e-7a71-4095-8895-a74c88ed9d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "model_path = \"ByteDance-Seed/Seed-X-PPO-7B-GPTQ-Int8\"\n",
    "\n",
    "model = LLM(\n",
    "    model=model_path,\n",
    "    max_num_seqs=512,\n",
    "    tensor_parallel_size=1,\n",
    "    enable_prefix_caching=True, \n",
    "    gpu_memory_utilization=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aa1425-7cf4-4207-86f8-329facfb5cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    \"\"\"\n",
    "Translate the following English sentence into Korean:\n",
    "So I think Yeah, that stays in your memory you keep remembering how big Manchester United is and so when I heard they were interested it was like Yeah, childhood dream.\n",
    "In my team in Antwerp there were some players who were also in England and when I talked to them about Manchester United you could directly see their face change.\n",
    "<ko>\n",
    "그래서 저는 그래요, 그건 당신의 기억에 남아있어요. 당신은 맨체스터 유나이티드가 얼마나 큰지 계속 기억하고 있고, 그래서 저가 그들이 관심이 있다는 것을 들었을 때는 마치 어린 시절의 꿈 같았어요.\"\"\",\n",
    "]\n",
    "\n",
    "# Sampling\n",
    "decoding_params = SamplingParams(temperature=0.1,\n",
    "                                 max_tokens=512,\n",
    "                                 skip_special_tokens=True)\n",
    "\n",
    "results = model.generate(messages, decoding_params)\n",
    "responses = [res.outputs[0].text.strip() for res in results]\n",
    "\n",
    "print(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98de11b2-4c90-4f5d-a1b3-0acfffb7d1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    \"\"\"\n",
    "Translate the following English sentence into Korean:\n",
    "In my team in Antwerp there were some players who were also in England and when I talked to them about Manchester United you could directly see their face change.\n",
    "<ko>\n",
    "\"\"\",\n",
    "]\n",
    "\n",
    "# Sampling\n",
    "decoding_params = SamplingParams(temperature=0.1,\n",
    "                                 max_tokens=512,\n",
    "                                 skip_special_tokens=True)\n",
    "\n",
    "import time\n",
    "st = time.time()\n",
    "results = model.generate(messages, decoding_params)\n",
    "print(time.time() - st)\n",
    "responses = [res.outputs[0].text.strip() for res in results]\n",
    "\n",
    "print(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b27eeba-f2b0-4041-8502-74c81b321c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd79cea9-f208-4610-a4ec-ceb25d84c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Callable\n",
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "OPENAI_KEY = os.environ.get(\"OPENAI_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_KEY)\n",
    "\n",
    "totals = 0\n",
    "for _ in range(12):\n",
    "    st = time.time()\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4.1-mini',  # 최신 경량 모델\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a professional translator specializing in [English] → [Korean] translation. Your job is to incrementally translate Korean speech as it comes in.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"\n",
    "Translate the following English sentence into Korean:\n",
    "So I think Yeah, that stays in your memory you keep remembering how big Manchester United is and so when I heard they were interested it was like Yeah, childhood dream.<ko>\n",
    "그래서 저는 그래요, 그건 당신의 기억에 남아있어요. 당신은 맨체스터 유나이티드가 얼마나 큰지 계속 기억하고 있고, 그래서 저가 그들이 관심이 있다는 것을 들었을 때는 마치...\n",
    "\"\"\"}\n",
    "        ],\n",
    "        temperature=0.4,\n",
    "        user=\"k2e-translator-v1-hojinkhj6051230808\",\n",
    "        prompt_cache_key=\"k2e-translator-v1-hojinkhj6051230808\",\n",
    "        # stream=True,\n",
    "        # stream_options={\"include_usage\": True},\n",
    "    )\n",
    "    \n",
    "    # sent = ''\n",
    "    \n",
    "    # pt = 0\n",
    "    # pt_cached = 0\n",
    "    # ct = 0\n",
    "    \n",
    "    # for chunk in response:\n",
    "    #     if chunk.usage and chunk.usage is not None:\n",
    "    #         if pt == 0:\n",
    "    #             # print(time.time() - st)\n",
    "    #             pt += 1\n",
    "    #         pass\n",
    "    #     else:\n",
    "    #         if chunk.choices[0].delta.content != '' and chunk.choices[0].delta.content is not None:\n",
    "    #             sent += chunk.choices[0].delta.content\n",
    "    \n",
    "    print(time.time() - st, \"\\n\", response)\n",
    "    totals += time.time() - st\n",
    "print(totals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b1cbdc-ce39-46a3-a28d-8a88a0361250",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(\"And there's a dimension of human intelligence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4d2562-373b-4019-a01e-ad61f33b2e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def text_pr(old, new):\n",
    "    # old, new 둘 다 소문자로 변환\n",
    "    o = old.lower()\n",
    "    n = new.lower()\n",
    "\n",
    "    # 공백과 콤마 제거\n",
    "    o_clean = re.sub(r\"[ ,]\", \"\", o)\n",
    "    n_clean = re.sub(r\"[ ,]\", \"\", n)\n",
    "\n",
    "    # 공통 prefix 찾기\n",
    "    i = 0\n",
    "    while i < len(o_clean) and i < len(n_clean) and o_clean[i] == n_clean[i]:\n",
    "        i += 1\n",
    "\n",
    "    # old는 공통 부분까지만, 나머지는 new에서 가져오기\n",
    "    return new[:i] + new[i:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cc034e-31e5-4a3c-88bf-d25ba18649af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def text_pr(old, new):\n",
    "    # old, new 둘 다 소문자로 변환\n",
    "    o = old.lower()\n",
    "    n = new.lower()\n",
    "\n",
    "    # 공백과 콤마 제거\n",
    "    o_clean = re.sub(r\"[ ,.]\", \"\", o)\n",
    "    n_clean = re.sub(r\"[ ,.]\", \"\", n)\n",
    "\n",
    "    # 공통 prefix 찾기\n",
    "    i = 0\n",
    "    while i < len(o_clean) and i < len(n_clean) and o_clean[i] == n_clean[i]:\n",
    "        i += 1\n",
    "\n",
    "    # old는 공통 부분까지만, 나머지는 new에서 가져오기\n",
    "    return old[:i] + new[i:]\n",
    "\n",
    "old = 'So you stop saving in U S government bonds and you start saving in the hardest money around, which is Bitcoin.'\n",
    "new = 'So you stop saving in US government bonds and you start saving in the hardest money around, which is Bitcoin.'\n",
    "\n",
    "text_pr(old, new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64de166c-2011-47aa-aee3-0c85f7b6b62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ['So you stop saving in US government.',\n",
    "'So you stop saving in US government bonds.',\n",
    "'So you stop saving in US government bonds and you',\n",
    "'So you stop saving in US government bonds and you start',\n",
    "'So you stop saving in US government bonds and you start saving.',\n",
    "'So you stop saving in US government bonds and you start saving',\n",
    "'So you stop saving in US government bonds and you start saving',\n",
    "'So you stop saving in U.S. government bonds and you start saving in the hard',\n",
    "'So you stop saving in U.S. government bonds and you start saving in the hardest way.',\n",
    "'So you stop saving in US government bonds and you start saving in the hardest money around.',\n",
    "'So you stop saving in U.S. government bonds and you start saving in the hardest money around.',\n",
    "'So you stop saving in U.S. government bonds and you start saving in the hardest money around, which is Bitcoin.',\n",
    "'So you stop saving in US government bonds and you start saving in the hardest money around, which is Bitcoin.',\n",
    "'So you stop saving in US government bonds and you start saving in the hardest money around, which is Bitcoin.',\n",
    "'So you stop saving in U S government bonds and you start saving in the hardest money around, which is Bitcoin.',\n",
    "]\n",
    "\n",
    "tt = ''\n",
    "for t in texts:\n",
    "    tt = text_pr(tt, t)\n",
    "    print(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c7454c-1b1d-4e8d-bfa0-573c5a186bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = ['weaf', '222', '333', '444', '555']\n",
    "\n",
    "text = \"\\n\".join([f\"<{x}>\" for x in ss])\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fc8015-d4a2-4a9e-b5a1-ddfa24711fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'de' in {'de': 123}.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05624cae-cb29-42e6-aba0-266203607a51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100ceabc-f04c-4b21-beb6-7326693be9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stt.asr import load_asr_backend\n",
    "ASR = load_asr_backend(kind=\"nemo\", device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fdd50f-6344-46d5-8bbe-6001e3de5fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "audio, sr = librosa.load(\"./utils/individualAudio.wav\", mono=True, sr=16000)\n",
    "# audio = torch.tensor(audio).to('cuda')\n",
    "pcm_bytes = (np.clip(audio, -1.0, 1.0) * 32767.0).astype(np.int16).tobytes()\n",
    "\n",
    "st = time.time()\n",
    "ASR.transcribe_pcm(pcm_bytes, sr, 1, language=\"english\")\n",
    "print(time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95db786f-37f9-47f1-8d04-a9814c2c68c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfe5693-342d-4d99-9616-6ea8eb22d6c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd469093-36d9-45cd-a320-0cde0a291d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm.openai_test import translate_simple\n",
    "import os\n",
    "from typing import Callable\n",
    "from openai import OpenAI\n",
    "\n",
    "OPENAI_KEY = os.environ.get(\"OPENAI_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_KEY)\n",
    "\n",
    "def translate_simple(prevScripts:str, current_scripted_sentence:str):\n",
    "    hist = \"\\n\".join([f\" me:{x},\" for x in prevScripts])\n",
    "\n",
    "    st = time.time()\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4.1-mini',  # 최신 경량 모델\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a professional translator specializing in [Korean] → [English] translation.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"\n",
    "지금 계속 한글로 말하는걸 영어로 번역하고 있어.\n",
    "<previous utterances>는 현재 문장 이전에 이야기하던 문장이야. 번역을 위한 맥락 파악에 사용할 수 있어.\n",
    "<speaking english>은 번역해야하는 현재 발화야.\n",
    "\n",
    "말을 하는걸 script로 만든 input이기 때문에, 발음 문제로 인해서 텍스트가 잘못 들어왔을 수 있어. 그걸 감안해서 번역해줘.\n",
    "\n",
    "출력 english를 일반 글 문장보다는 실제로 사람이 말하는 것 같은 구어체로 적어줘. 예를 들어, Oh, Ah, uhm..을 쓰거나 아님 같은 단어를 두번 쓰거나 이런 것들 있잖아?\n",
    "Translate into casual spoken English. 근데 너무 심하게 하진 말고, 없는 말을 만들거나 들어온 input을 왜곡하면 안돼.\n",
    "\n",
    "-- INPUT --\n",
    "<previous utterances>{hist}\n",
    "<speaking korean> : {current_scripted_sentence}\n",
    "<english> : \n",
    "\"\"\"}\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "        user=\"k2e-translator-v1-hojinkhj6051230808\",\n",
    "        prompt_cache_key=\"k2e-translator-v1-hojinkhj6051230808\",\n",
    "        stream=True,\n",
    "    )\n",
    "    sent = ''\n",
    "    for chunk in response:\n",
    "        if chunk.usage and chunk.usage is not None:\n",
    "            u = chunk.usage;\n",
    "        else:\n",
    "            if chunk.choices[0].delta.content != '' and chunk.choices[0].delta.content is not None:\n",
    "                print(time.time() - st, \"-\", chunk.choices[0].delta.content)\n",
    "                sent += chunk.choices[0].delta.content\n",
    "            if chunk.choices[0].finish_reason is not None:\n",
    "                print(\"END RETURN!\", time.time() - st)\n",
    "                return sent\n",
    "\n",
    "    return sent\n",
    "\n",
    "def tt(token):\n",
    "    pass\n",
    "\n",
    "sts = time.time()\n",
    "result = translate_simple(\"\", \"아 아 그건 좀 아닌 것 같은데.. 오늘은 뭐 먹을까?ㅋㅋ 맛난거 먹자\")\n",
    "print(result, time.time() - sts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3159b5e-d4e6-4fea-891e-c0cfdfdd78d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "ctx = load_infer_context({\n",
    "    \"model_name\": \"zipvoice\",\n",
    "    \"model_dir\": None,\n",
    "    \"checkpoint_name\": \"model.pt\",\n",
    "    \"vocoder_path\": None,\n",
    "    \"tokenizer\": \"emilia\",\n",
    "    \"lang\": \"en-us\",\n",
    "    \"num_step\": 32,\n",
    "    \"guidance_scale\": None,\n",
    "    \"feat_scale\": 0.1,\n",
    "    \"speed\": 0.9,\n",
    "    \"t_shift\": 0.5,\n",
    "    \"target_rms\": 0.1,\n",
    "})\n",
    "\n",
    "wav, info = generate_sentence(\n",
    "    prompt_text='Ahh you flipped on me, Oh, that smooth. Honestly, Pretty chill, just existing, you know.',\n",
    "    prompt_wav_path='./denoised.wav',\n",
    "    text=result,\n",
    "    ctx=ctx,\n",
    ")\n",
    "\n",
    "display(Audio(wav, rate=24000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cb62c0-8edc-4bbc-9c4a-ea68ce2f59c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "audio = AudioSegment.from_file(\"./tts/voice.wav\")\n",
    "display(Audio(\"./tts/voice.wav\"))\n",
    "# 앞 0.1초 (100ms) 추출\n",
    "first_100ms = audio[:800]  # 밀리초 단위\n",
    "\n",
    "# 새로운 파일로 저장\n",
    "first_100ms.export(\"output.wav\", format=\"wav\")\n",
    "display(Audio(\"output.wav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5846f6c4-e353-4590-b068-fe2bf1933de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "audio = AudioSegment.from_file(\"./sam.m4a\")\n",
    "first_100ms = audio[:-500]  # 밀리초 단위\n",
    "first_100ms.export(\"output.wav\", format=\"wav\")\n",
    "display(Audio(\"output.wav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495ccde1-e3d4-49b8-a873-a5534653ba90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipvoice.tokenizer.tokenizer import EmiliaTokenizer\n",
    "\n",
    "tokenizer = EmiliaTokenizer(token_file=\"/workspace/ttssocketserver/tts/tokens.txt\")\n",
    "\n",
    "print(tokenizer.texts_to_tokens([\"안녕하세요, what's happening? 霍...啦啦啦超过\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841389f1-11ea-4ce8-ab5c-97512384db68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import noisereduce as nr\n",
    "import soundfile as sf\n",
    "\n",
    "y, sr = librosa.load(\"./output.wav\", sr=None)\n",
    "\n",
    "noise_clip = y[:int(sr*0.3)]\n",
    "\n",
    "reduced_audio = nr.reduce_noise(y=y, sr=sr, y_noise=noise_clip)\n",
    "\n",
    "sf.write(\"denoised.wav\", reduced_audio, sr)\n",
    "\n",
    "display(Audio(reduced_audio, rate=48000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aa6918-4419-49f4-9569-d71392a4369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm.openai_test import translate_simple\n",
    "import time\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "def tes(tk):\n",
    "    print(time.time() - st, tk)\n",
    "\n",
    "res = translate_simple(\"\", \"안녕하세요 밥이나 잡수시죠?\", \"\", tes)\n",
    "print(time.time() - st)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dc3817-8f51-4d8a-b2bf-b5e0cddbadef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "y, sr = librosa.load(\"./output.wav\", sr=24000)\n",
    "print(y.shape, y.min(), y.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5182595c-0a54-4422-b145-60746cc8e415",
   "metadata": {},
   "outputs": [],
   "source": [
    "from librosa.util import normalize\n",
    "\n",
    "yy = normalize(y) * 0.95\n",
    "print(yy.min(), yy.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a25487-476f-44ca-a090-158513dfc32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import librosa\n",
    "\n",
    "filler_audios_path = [\"./utils/hmhm.wav\", \"./utils/uhuh.wav\", \"./utils/ohoh.wav\", \"./utils/uhmuhm.wav\"]\n",
    "filler_audios = []\n",
    "for p in filler_audios_path:\n",
    "    audiod, sr = librosa.load(p, sr=24000, mono=True)\n",
    "    audiod = torch.tensor(audiod)\n",
    "    filler_audios.append(audiod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89c5090-dec9-43bf-92de-3f56c5cfc6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "audiod.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd45bd3a-f51c-46d1-b6c5-b56b204b1cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import queue\n",
    "\n",
    "aa = queue.Queue()\n",
    "aa.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a517e674-f532-4e0e-8823-e6fea9cc5a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a11683-a25a-4824-b230-a20d5d44aa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatterbox_infer.mtl_tts import ChatterboxMultilingualTTS\n",
    "tts_model = ChatterboxMultilingualTTS.from_pretrained(device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6461bb7e-1784-4171-a071-2689f4a36d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "res = tts_model.generate(\n",
    "        \"Hm.. I'm planning to head to San Francisco... around next week, and..\",\n",
    "        language_id='en',\n",
    "        audio_prompt_path=\"./a3.wav\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa54e62-1abb-469c-8aaa-0de9c75024d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "display(Audio(res.cpu().numpy(), rate=24000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c08a9df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecab44a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "async for event in tts_model.generate_stream(\n",
    "        \"I don't know. where are you going?\",\n",
    "        language_id='en',\n",
    "        audio_prompt_path=\"./hmhm.wav\"\n",
    "    ):\n",
    "    if event.get(\"type\") == \"eos\":\n",
    "        print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5403295f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "async for event in tts_model.generate_stream(\n",
    "        \"I don't know. where are you going?\",\n",
    "        language_id='en',\n",
    "        audio_prompt_path=\"./hmhm.wav\"\n",
    "    ):\n",
    "    if event.get(\"type\") == \"eos\":\n",
    "        print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be84fb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatterbox_infer.tts import ChatterboxTTS\n",
    "tts_model = ChatterboxTTS.from_pretrained(device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32e9571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "i=0\n",
    "start_time = time.time()\n",
    "async for event in tts_model.generate_stream(\n",
    "        \"I don't know. where are you going?\",\n",
    "        audio_prompt_path=\"./hmhm.wav\"\n",
    "    ):\n",
    "    print(f\"{i}th - \", time.time() - start_time)\n",
    "    i += 1\n",
    "    start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6547e9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "i=0\n",
    "start_time = time.time()\n",
    "async for event in tts_model.generate_stream(\n",
    "        \"I don't know. where are you going?\",\n",
    "        language_id='en',\n",
    "        audio_prompt_path=\"./hmhm.wav\"\n",
    "    ):\n",
    "    print(f\"{i}th - \", time.time() - start_time)\n",
    "    i += 1\n",
    "    start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e125532",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
