{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa38be10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we should go to the market market, okay?\n",
      "0.0001285076141357422\n"
     ]
    }
   ],
   "source": [
    "from utils.text_process import text_pr\n",
    "import time\n",
    "\n",
    "st = time.time()\n",
    "print(text_pr(\"we should go to the market\", \"so to the market, okay?\"))\n",
    "print(time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de11be37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='gwan.wav'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "# m4a 불러오기\n",
    "audio = AudioSegment.from_file(\"gwan.m4a\", format=\"m4a\")\n",
    "\n",
    "# wav로 저장\n",
    "audio.export(\"gwan.wav\", format=\"wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fc0f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Callable\n",
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "OPENAI_KEY = os.environ.get(\"OPENAI_KEY\")\n",
    "\n",
    "LANGUAGE_CODE = {\n",
    "    \"Arabic\": \"ar\",\n",
    "    \"Danish\": \"da\",\n",
    "    \"German\": \"de\",\n",
    "    \"Greek\": \"el\",\n",
    "    \"English\": \"en\",\n",
    "    \"Spanish\": \"es\",\n",
    "    \"Finnish\": \"fi\",\n",
    "    \"French\": \"fr\",\n",
    "    \"Hebrew\": \"he\",\n",
    "    \"Hindi\": \"hi\",\n",
    "    \"Italian\": \"it\",\n",
    "    \"Japanese\": \"ja\",\n",
    "    \"Korean\": \"ko\",\n",
    "    \"Malay\": \"ms\",\n",
    "    \"Dutch\": \"nl\",\n",
    "    \"Norwegian\": \"no\",\n",
    "    \"Polish\": \"pl\",\n",
    "    \"Portuguese\": \"pt\",\n",
    "    \"Russian\": \"ru\",\n",
    "    \"Swedish\": \"sv\",\n",
    "    \"Swahili\": \"sw\",\n",
    "    \"Turkish\": \"tr\",\n",
    "    \"Chinese\": \"zh\",\n",
    "}\n",
    "\n",
    "LANGUAGE_CODE_REVERSED = {v: k for k, v in LANGUAGE_CODE.items()}\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_KEY)\n",
    "\n",
    "def translate(prevScripts:str, current_scripted_sentence:str, current_translated:str, onToken, input_language:str = 'Korean', output_language:str = 'English'):\n",
    "    hist = \"\\n\".join([f\" me:{x},\" for x in prevScripts])\n",
    "    input_language = LANGUAGE_CODE_REVERSED[input_language]\n",
    "    output_language = LANGUAGE_CODE_REVERSED[output_language]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4.1-mini',  # 최신 경량 모델\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": f\"You are a professional translator specializing in [{input_language}] → [{output_language}] translation.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"\n",
    "You are translating {input_language} speech into {output_language}.\n",
    "\n",
    "<previous utterances> are the sentences spoken before the current one. Use them for context.  \n",
    "<speaking korean> is the current spoken input that needs to be translated.  \n",
    "<{output_language}> is the translation generated so far.  \n",
    "\n",
    "The input comes from speech-to-text, so there may be transcription errors due to pronunciation. Please take this into account when translating.  \n",
    "\n",
    "Output the translation in casual spoken {output_language} — like how people actually talk, with natural pauses, repetitions, or fillers such as “...” or “!” — but don’t overdo it. Do not invent new words or distort the original meaning.  \n",
    "Do not start with words like “Oh”, “So”, “Uhm”, or “Huh”.  \n",
    "\n",
    "If the {input_language} input seems incomplete (cut off mid-sentence), output an unfinished {output_language} sentence too, so it can be naturally continued. You don’t need to force a full translation of every fragment if it isn’t complete yet.\n",
    "한글 종결 어미의 특징 : ~~요. ~~니다. ~~어.\n",
    "\n",
    "\n",
    "Continue from existing {output_language} translation.  \n",
    "Do not echo or include the existing translation in the output — return only the newly translated continuation.\n",
    "\n",
    "- If more input is likely to follow, end with `...`.\n",
    "- If the current {input_language} input + context forms a COMPLETE sentence in {output_language}, Do not end with `...`.\n",
    "\n",
    "# Real-Time Translation Tips\n",
    "1. **Avoid Premature Subject Translation**\n",
    "- Korean often omits or ambiguates the subject.\n",
    "- When the subject is unclear, try to infer it from prior context.\n",
    "- If there’s even slight ambiguity, avoid explicitly translating the subject (\"I\", \"we\", \"they\", etc.) and use neutral or impersonal expressions instead.\n",
    "- Example:\n",
    "  - Korean: “마케팅비를 청구해야 한다”\n",
    "  - Preferred: “Marketing costs must also be claimed.”\n",
    "  - Not: “I should claim the marketing costs.”\n",
    "- Example:\n",
    "  - Korean: \"내일 집에\"\n",
    "  - Preferred: \"Tomorrow,\"\n",
    "  - Not: \"Tomorrow at home, I'll \"\n",
    "\n",
    "2. Do not include the verb in the translation if no verb is spoken.\n",
    "- Korean places verbs at the end. Don't translate prematurely if the action is unknown.\n",
    "- Example: “운동장에가서 축구를…”\n",
    "  - Preferred: \"I'll go to the sports field and...\" # Still don't know whether they will play soccer or watch. Just skip the sentence, because there will be more input to come next.\n",
    "  - Not: \"I'll go to the sports field and play soccer...\" # This is not correct, because next input can be \"축구를 봤어.\"\n",
    "- Example: \"오늘 아침에 밥을\"\n",
    "  - Preferred: \"This morning,\" # Still don't know whether they will eat breakfast or not. You dont have to include all words in the input.\n",
    "  - Not: \"I had breakfast this morning.\"\n",
    "\n",
    "3. 실제 대화처럼, speaking으로 들어온 사소한 말버릇 까지도 번역에 포함해줘.\n",
    "- Example: \"저기, 어… 우리 우리 그때 같이 갔던 카페 있잖아.\"\n",
    "  - Preferred: \"Hey, um… you know, that café we, we went to back then?\"\n",
    "  - Not: \"You know that café we went to back then?\"\n",
    "같은 단어를 반복하면, 번역도 반복해줘.\n",
    "\n",
    "-- INPUT --  \n",
    "<previous utterances> {hist}  \n",
    "<speaking {input_language}> : {current_scripted_sentence}  \n",
    "<{output_language}> : {current_translated}\n",
    "\"\"\"}\n",
    "        ],\n",
    "        temperature=0.8,\n",
    "        user=\"k2e-translator-v1-hojinkhj6051230808\",\n",
    "        prompt_cache_key=\"k2e-translator-v1-hojinkhj6051230808\",\n",
    "        stream=True,\n",
    "        stream_options={\"include_usage\": True},\n",
    "    )\n",
    "\n",
    "    sent = ''\n",
    "    first = 0\n",
    "    st = time.time()\n",
    "\n",
    "    pt = 0\n",
    "    pt_cached = 0\n",
    "    ct = 0\n",
    "\n",
    "    for chunk in response:\n",
    "        if chunk.usage and chunk.usage is not None:\n",
    "            u = chunk.usage;\n",
    "            pt += u.prompt_tokens\n",
    "            pt_cached += u.prompt_tokens_details.cached_tokens\n",
    "            ct += u.completion_tokens\n",
    "        else:\n",
    "            if chunk.choices[0].delta.content != '' and chunk.choices[0].delta.content is not None:\n",
    "                onToken(chunk.choices[0].delta.content)\n",
    "                sent += chunk.choices[0].delta.content\n",
    "\n",
    "    return {\n",
    "        \"text\": sent,\n",
    "        \"prompt_tokens\": pt,\n",
    "        \"prompt_tokens_cached\": pt_cached,\n",
    "        \"completion_tokens\": ct\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a8333c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'What was today’s, like, meeting about again?', 'prompt_tokens': 767, 'prompt_tokens_cached': 0, 'completion_tokens': 11}\n"
     ]
    }
   ],
   "source": [
    "output2 = translate([], f\"오늘 어 오늘 회의가 뭐였죠?\", \"\", lambda x: None, input_language=\"ko\", output_language=\"en\")\n",
    "print(output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29afab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([216360])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41583911-fbbb-4604-a73f-cef3df232bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"trillionlabs/Tri-1.8B-Translation\",\n",
    "    dtype=\"float16\",               # GPU라면 권장\n",
    "    tensor_parallel_size=1,        # 단일 GPU 보장\n",
    "    enforce_eager=True,            # CUDA graph 캡쳐 이슈 회피\n",
    "    gpu_memory_utilization=0.5,   # 메모리 여유 확보\n",
    "    disable_log_stats=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b618c23d-68ef-4d74-80ba-ea2bd31c61f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = SamplingParams(temperature=0.1, max_tokens=512)\n",
    "\n",
    "target = \"ko\"\n",
    "text = \"\"\"There's so much to do on a day like this, lots of things to do, but maybe later when you're having dinner.\"\"\"\n",
    "\n",
    "prompt_old = f\"\"\"\n",
    "Translate into ko\\n\n",
    "{text}<ko>\n",
    "이런 날에는 할 일이 너무 많고 할 일도 많지만, 나중에 저녁을 먹을 때쯤이면.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Translate into ko\\n\n",
    "There will be a chance to reflect.<ko>\n",
    "\"\"\"\n",
    "out = llm.chat([{\"role\": \"user\", \"content\": prompt}], sampling_params=sp)\n",
    "out[0].outputs[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2004363e-f612-4b01-b993-37aa3a17c527",
   "metadata": {},
   "outputs": [],
   "source": [
    "out[0].outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a137b4-10f7-499f-b0ba-084fb76867d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd8b09e-7a71-4095-8895-a74c88ed9d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "model_path = \"ByteDance-Seed/Seed-X-PPO-7B-GPTQ-Int8\"\n",
    "\n",
    "model = LLM(\n",
    "    model=model_path,\n",
    "    max_num_seqs=512,\n",
    "    tensor_parallel_size=1,\n",
    "    enable_prefix_caching=True, \n",
    "    gpu_memory_utilization=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aa1425-7cf4-4207-86f8-329facfb5cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    \"\"\"\n",
    "Translate the following English sentence into Korean:\n",
    "So I think Yeah, that stays in your memory you keep remembering how big Manchester United is and so when I heard they were interested it was like Yeah, childhood dream.\n",
    "In my team in Antwerp there were some players who were also in England and when I talked to them about Manchester United you could directly see their face change.\n",
    "<ko>\n",
    "그래서 저는 그래요, 그건 당신의 기억에 남아있어요. 당신은 맨체스터 유나이티드가 얼마나 큰지 계속 기억하고 있고, 그래서 저가 그들이 관심이 있다는 것을 들었을 때는 마치 어린 시절의 꿈 같았어요.\"\"\",\n",
    "]\n",
    "\n",
    "# Sampling\n",
    "decoding_params = SamplingParams(temperature=0.1,\n",
    "                                 max_tokens=512,\n",
    "                                 skip_special_tokens=True)\n",
    "\n",
    "results = model.generate(messages, decoding_params)\n",
    "responses = [res.outputs[0].text.strip() for res in results]\n",
    "\n",
    "print(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98de11b2-4c90-4f5d-a1b3-0acfffb7d1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    \"\"\"\n",
    "Translate the following English sentence into Korean:\n",
    "In my team in Antwerp there were some players who were also in England and when I talked to them about Manchester United you could directly see their face change.\n",
    "<ko>\n",
    "\"\"\",\n",
    "]\n",
    "\n",
    "# Sampling\n",
    "decoding_params = SamplingParams(temperature=0.1,\n",
    "                                 max_tokens=512,\n",
    "                                 skip_special_tokens=True)\n",
    "\n",
    "import time\n",
    "st = time.time()\n",
    "results = model.generate(messages, decoding_params)\n",
    "print(time.time() - st)\n",
    "responses = [res.outputs[0].text.strip() for res in results]\n",
    "\n",
    "print(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b27eeba-f2b0-4041-8502-74c81b321c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd79cea9-f208-4610-a4ec-ceb25d84c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Callable\n",
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "OPENAI_KEY = os.environ.get(\"OPENAI_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_KEY)\n",
    "\n",
    "totals = 0\n",
    "for _ in range(12):\n",
    "    st = time.time()\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4.1-mini',  # 최신 경량 모델\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a professional translator specializing in [English] → [Korean] translation. Your job is to incrementally translate Korean speech as it comes in.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"\n",
    "Translate the following English sentence into Korean:\n",
    "So I think Yeah, that stays in your memory you keep remembering how big Manchester United is and so when I heard they were interested it was like Yeah, childhood dream.<ko>\n",
    "그래서 저는 그래요, 그건 당신의 기억에 남아있어요. 당신은 맨체스터 유나이티드가 얼마나 큰지 계속 기억하고 있고, 그래서 저가 그들이 관심이 있다는 것을 들었을 때는 마치...\n",
    "\"\"\"}\n",
    "        ],\n",
    "        temperature=0.4,\n",
    "        user=\"k2e-translator-v1-hojinkhj6051230808\",\n",
    "        prompt_cache_key=\"k2e-translator-v1-hojinkhj6051230808\",\n",
    "        # stream=True,\n",
    "        # stream_options={\"include_usage\": True},\n",
    "    )\n",
    "    \n",
    "    # sent = ''\n",
    "    \n",
    "    # pt = 0\n",
    "    # pt_cached = 0\n",
    "    # ct = 0\n",
    "    \n",
    "    # for chunk in response:\n",
    "    #     if chunk.usage and chunk.usage is not None:\n",
    "    #         if pt == 0:\n",
    "    #             # print(time.time() - st)\n",
    "    #             pt += 1\n",
    "    #         pass\n",
    "    #     else:\n",
    "    #         if chunk.choices[0].delta.content != '' and chunk.choices[0].delta.content is not None:\n",
    "    #             sent += chunk.choices[0].delta.content\n",
    "    \n",
    "    print(time.time() - st, \"\\n\", response)\n",
    "    totals += time.time() - st\n",
    "print(totals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b1cbdc-ce39-46a3-a28d-8a88a0361250",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(\"And there's a dimension of human intelligence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4d2562-373b-4019-a01e-ad61f33b2e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def text_pr(old, new):\n",
    "    # old, new 둘 다 소문자로 변환\n",
    "    o = old.lower()\n",
    "    n = new.lower()\n",
    "\n",
    "    # 공백과 콤마 제거\n",
    "    o_clean = re.sub(r\"[ ,]\", \"\", o)\n",
    "    n_clean = re.sub(r\"[ ,]\", \"\", n)\n",
    "\n",
    "    # 공통 prefix 찾기\n",
    "    i = 0\n",
    "    while i < len(o_clean) and i < len(n_clean) and o_clean[i] == n_clean[i]:\n",
    "        i += 1\n",
    "\n",
    "    # old는 공통 부분까지만, 나머지는 new에서 가져오기\n",
    "    return new[:i] + new[i:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cc034e-31e5-4a3c-88bf-d25ba18649af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def text_pr(old, new):\n",
    "    # old, new 둘 다 소문자로 변환\n",
    "    o = old.lower()\n",
    "    n = new.lower()\n",
    "\n",
    "    # 공백과 콤마 제거\n",
    "    o_clean = re.sub(r\"[ ,.]\", \"\", o)\n",
    "    n_clean = re.sub(r\"[ ,.]\", \"\", n)\n",
    "\n",
    "    # 공통 prefix 찾기\n",
    "    i = 0\n",
    "    while i < len(o_clean) and i < len(n_clean) and o_clean[i] == n_clean[i]:\n",
    "        i += 1\n",
    "\n",
    "    # old는 공통 부분까지만, 나머지는 new에서 가져오기\n",
    "    return old[:i] + new[i:]\n",
    "\n",
    "old = 'So you stop saving in U S government bonds and you start saving in the hardest money around, which is Bitcoin.'\n",
    "new = 'So you stop saving in US government bonds and you start saving in the hardest money around, which is Bitcoin.'\n",
    "\n",
    "text_pr(old, new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64de166c-2011-47aa-aee3-0c85f7b6b62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ['So you stop saving in US government.',\n",
    "'So you stop saving in US government bonds.',\n",
    "'So you stop saving in US government bonds and you',\n",
    "'So you stop saving in US government bonds and you start',\n",
    "'So you stop saving in US government bonds and you start saving.',\n",
    "'So you stop saving in US government bonds and you start saving',\n",
    "'So you stop saving in US government bonds and you start saving',\n",
    "'So you stop saving in U.S. government bonds and you start saving in the hard',\n",
    "'So you stop saving in U.S. government bonds and you start saving in the hardest way.',\n",
    "'So you stop saving in US government bonds and you start saving in the hardest money around.',\n",
    "'So you stop saving in U.S. government bonds and you start saving in the hardest money around.',\n",
    "'So you stop saving in U.S. government bonds and you start saving in the hardest money around, which is Bitcoin.',\n",
    "'So you stop saving in US government bonds and you start saving in the hardest money around, which is Bitcoin.',\n",
    "'So you stop saving in US government bonds and you start saving in the hardest money around, which is Bitcoin.',\n",
    "'So you stop saving in U S government bonds and you start saving in the hardest money around, which is Bitcoin.',\n",
    "]\n",
    "\n",
    "tt = ''\n",
    "for t in texts:\n",
    "    tt = text_pr(tt, t)\n",
    "    print(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c7454c-1b1d-4e8d-bfa0-573c5a186bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = ['weaf', '222', '333', '444', '555']\n",
    "\n",
    "text = \"\\n\".join([f\"<{x}>\" for x in ss])\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fc8015-d4a2-4a9e-b5a1-ddfa24711fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'de' in {'de': 123}.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05624cae-cb29-42e6-aba0-266203607a51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100ceabc-f04c-4b21-beb6-7326693be9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stt.asr import load_asr_backend\n",
    "ASR = load_asr_backend(kind=\"nemo\", device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fdd50f-6344-46d5-8bbe-6001e3de5fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "audio, sr = librosa.load(\"./utils/individualAudio.wav\", mono=True, sr=16000)\n",
    "# audio = torch.tensor(audio).to('cuda')\n",
    "pcm_bytes = (np.clip(audio, -1.0, 1.0) * 32767.0).astype(np.int16).tobytes()\n",
    "\n",
    "st = time.time()\n",
    "ASR.transcribe_pcm(pcm_bytes, sr, 1, language=\"english\")\n",
    "print(time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95db786f-37f9-47f1-8d04-a9814c2c68c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfe5693-342d-4d99-9616-6ea8eb22d6c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd469093-36d9-45cd-a320-0cde0a291d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm.openai_test import translate_simple\n",
    "import os\n",
    "from typing import Callable\n",
    "from openai import OpenAI\n",
    "\n",
    "OPENAI_KEY = os.environ.get(\"OPENAI_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_KEY)\n",
    "\n",
    "def translate_simple(prevScripts:str, current_scripted_sentence:str):\n",
    "    hist = \"\\n\".join([f\" me:{x},\" for x in prevScripts])\n",
    "\n",
    "    st = time.time()\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4.1-mini',  # 최신 경량 모델\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a professional translator specializing in [Korean] → [English] translation.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"\n",
    "지금 계속 한글로 말하는걸 영어로 번역하고 있어.\n",
    "<previous utterances>는 현재 문장 이전에 이야기하던 문장이야. 번역을 위한 맥락 파악에 사용할 수 있어.\n",
    "<speaking english>은 번역해야하는 현재 발화야.\n",
    "\n",
    "말을 하는걸 script로 만든 input이기 때문에, 발음 문제로 인해서 텍스트가 잘못 들어왔을 수 있어. 그걸 감안해서 번역해줘.\n",
    "\n",
    "출력 english를 일반 글 문장보다는 실제로 사람이 말하는 것 같은 구어체로 적어줘. 예를 들어, Oh, Ah, uhm..을 쓰거나 아님 같은 단어를 두번 쓰거나 이런 것들 있잖아?\n",
    "Translate into casual spoken English. 근데 너무 심하게 하진 말고, 없는 말을 만들거나 들어온 input을 왜곡하면 안돼.\n",
    "\n",
    "-- INPUT --\n",
    "<previous utterances>{hist}\n",
    "<speaking korean> : {current_scripted_sentence}\n",
    "<english> : \n",
    "\"\"\"}\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "        user=\"k2e-translator-v1-hojinkhj6051230808\",\n",
    "        prompt_cache_key=\"k2e-translator-v1-hojinkhj6051230808\",\n",
    "        stream=True,\n",
    "    )\n",
    "    sent = ''\n",
    "    for chunk in response:\n",
    "        if chunk.usage and chunk.usage is not None:\n",
    "            u = chunk.usage;\n",
    "        else:\n",
    "            if chunk.choices[0].delta.content != '' and chunk.choices[0].delta.content is not None:\n",
    "                print(time.time() - st, \"-\", chunk.choices[0].delta.content)\n",
    "                sent += chunk.choices[0].delta.content\n",
    "            if chunk.choices[0].finish_reason is not None:\n",
    "                print(\"END RETURN!\", time.time() - st)\n",
    "                return sent\n",
    "\n",
    "    return sent\n",
    "\n",
    "def tt(token):\n",
    "    pass\n",
    "\n",
    "sts = time.time()\n",
    "result = translate_simple(\"\", \"아 아 그건 좀 아닌 것 같은데.. 오늘은 뭐 먹을까?ㅋㅋ 맛난거 먹자\")\n",
    "print(result, time.time() - sts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3159b5e-d4e6-4fea-891e-c0cfdfdd78d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "ctx = load_infer_context({\n",
    "    \"model_name\": \"zipvoice\",\n",
    "    \"model_dir\": None,\n",
    "    \"checkpoint_name\": \"model.pt\",\n",
    "    \"vocoder_path\": None,\n",
    "    \"tokenizer\": \"emilia\",\n",
    "    \"lang\": \"en-us\",\n",
    "    \"num_step\": 32,\n",
    "    \"guidance_scale\": None,\n",
    "    \"feat_scale\": 0.1,\n",
    "    \"speed\": 0.9,\n",
    "    \"t_shift\": 0.5,\n",
    "    \"target_rms\": 0.1,\n",
    "})\n",
    "\n",
    "wav, info = generate_sentence(\n",
    "    prompt_text='Ahh you flipped on me, Oh, that smooth. Honestly, Pretty chill, just existing, you know.',\n",
    "    prompt_wav_path='./denoised.wav',\n",
    "    text=result,\n",
    "    ctx=ctx,\n",
    ")\n",
    "\n",
    "display(Audio(wav, rate=24000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cb62c0-8edc-4bbc-9c4a-ea68ce2f59c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "audio = AudioSegment.from_file(\"./tts/voice.wav\")\n",
    "display(Audio(\"./tts/voice.wav\"))\n",
    "# 앞 0.1초 (100ms) 추출\n",
    "first_100ms = audio[:800]  # 밀리초 단위\n",
    "\n",
    "# 새로운 파일로 저장\n",
    "first_100ms.export(\"output.wav\", format=\"wav\")\n",
    "display(Audio(\"output.wav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5846f6c4-e353-4590-b068-fe2bf1933de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "audio = AudioSegment.from_file(\"./sam.m4a\")\n",
    "first_100ms = audio[:-500]  # 밀리초 단위\n",
    "first_100ms.export(\"output.wav\", format=\"wav\")\n",
    "display(Audio(\"output.wav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495ccde1-e3d4-49b8-a873-a5534653ba90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipvoice.tokenizer.tokenizer import EmiliaTokenizer\n",
    "\n",
    "tokenizer = EmiliaTokenizer(token_file=\"/workspace/ttssocketserver/tts/tokens.txt\")\n",
    "\n",
    "print(tokenizer.texts_to_tokens([\"안녕하세요, what's happening? 霍...啦啦啦超过\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841389f1-11ea-4ce8-ab5c-97512384db68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import noisereduce as nr\n",
    "import soundfile as sf\n",
    "\n",
    "y, sr = librosa.load(\"./output.wav\", sr=None)\n",
    "\n",
    "noise_clip = y[:int(sr*0.3)]\n",
    "\n",
    "reduced_audio = nr.reduce_noise(y=y, sr=sr, y_noise=noise_clip)\n",
    "\n",
    "sf.write(\"denoised.wav\", reduced_audio, sr)\n",
    "\n",
    "display(Audio(reduced_audio, rate=48000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aa6918-4419-49f4-9569-d71392a4369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm.openai_test import translate_simple\n",
    "import time\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "def tes(tk):\n",
    "    print(time.time() - st, tk)\n",
    "\n",
    "res = translate_simple(\"\", \"안녕하세요 밥이나 잡수시죠?\", \"\", tes)\n",
    "print(time.time() - st)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dc3817-8f51-4d8a-b2bf-b5e0cddbadef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "y, sr = librosa.load(\"./output.wav\", sr=24000)\n",
    "print(y.shape, y.min(), y.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5182595c-0a54-4422-b145-60746cc8e415",
   "metadata": {},
   "outputs": [],
   "source": [
    "from librosa.util import normalize\n",
    "\n",
    "yy = normalize(y) * 0.95\n",
    "print(yy.min(), yy.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a25487-476f-44ca-a090-158513dfc32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import librosa\n",
    "\n",
    "filler_audios_path = [\"./utils/hmhm.wav\", \"./utils/uhuh.wav\", \"./utils/ohoh.wav\", \"./utils/uhmuhm.wav\"]\n",
    "filler_audios = []\n",
    "for p in filler_audios_path:\n",
    "    audiod, sr = librosa.load(p, sr=24000, mono=True)\n",
    "    audiod = torch.tensor(audiod)\n",
    "    filler_audios.append(audiod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89c5090-dec9-43bf-92de-3f56c5cfc6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "audiod.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd45bd3a-f51c-46d1-b6c5-b56b204b1cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import queue\n",
    "\n",
    "aa = queue.Queue()\n",
    "aa.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a517e674-f532-4e0e-8823-e6fea9cc5a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a11683-a25a-4824-b230-a20d5d44aa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatterbox_infer.mtl_tts import ChatterboxMultilingualTTS\n",
    "tts_model = ChatterboxMultilingualTTS.from_pretrained(device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6461bb7e-1784-4171-a071-2689f4a36d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "res = tts_model.generate(\n",
    "        \"Hm.. I'm planning to head to San Francisco... around next week, and..\",\n",
    "        language_id='en',\n",
    "        audio_prompt_path=\"./a3.wav\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa54e62-1abb-469c-8aaa-0de9c75024d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "display(Audio(res.cpu().numpy(), rate=24000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c08a9df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecab44a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "async for event in tts_model.generate_stream(\n",
    "        \"I don't know. where are you going?\",\n",
    "        language_id='en',\n",
    "        audio_prompt_path=\"./hmhm.wav\"\n",
    "    ):\n",
    "    if event.get(\"type\") == \"eos\":\n",
    "        print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5403295f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "async for event in tts_model.generate_stream(\n",
    "        \"I don't know. where are you going?\",\n",
    "        language_id='en',\n",
    "        audio_prompt_path=\"./hmhm.wav\"\n",
    "    ):\n",
    "    if event.get(\"type\") == \"eos\":\n",
    "        print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be84fb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatterbox_infer.tts import ChatterboxTTS\n",
    "tts_model = ChatterboxTTS.from_pretrained(device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32e9571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "i=0\n",
    "start_time = time.time()\n",
    "async for event in tts_model.generate_stream(\n",
    "        \"I don't know. where are you going?\",\n",
    "        audio_prompt_path=\"./hmhm.wav\"\n",
    "    ):\n",
    "    print(f\"{i}th - \", time.time() - start_time)\n",
    "    i += 1\n",
    "    start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6547e9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "i=0\n",
    "start_time = time.time()\n",
    "async for event in tts_model.generate_stream(\n",
    "        \"I don't know. where are you going?\",\n",
    "        language_id='en',\n",
    "        audio_prompt_path=\"./hmhm.wav\"\n",
    "    ):\n",
    "    print(f\"{i}th - \", time.time() - start_time)\n",
    "    i += 1\n",
    "    start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e125532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Callable\n",
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "OPENAI_KEY = os.environ.get(\"OPENAI_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_KEY)\n",
    "\n",
    "def translate(prevScripts:str, current_scripted_sentence:str, current_translated:str, onToken, input_language:str = 'Korean', output_language:str = 'English'):\n",
    "    hist = \"\\n\".join([f\" me:{x},\" for x in prevScripts])\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4.1-mini',  # 최신 경량 모델\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": f\"You are a professional translator specializing in [{input_language}] → [{output_language}] translation.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"\n",
    "You are translating {input_language} speech into {output_language}.\n",
    "\n",
    "<previous utterances> are the sentences spoken before the current one. Use them for context.  \n",
    "<speaking korean> is the current spoken input that needs to be translated.  \n",
    "<{output_language}> is the translation generated so far.  \n",
    "\n",
    "The input comes from speech-to-text, so there may be transcription errors due to pronunciation. Please take this into account when translating.  \n",
    "\n",
    "Output the translation in casual spoken {output_language} — like how people actually talk, with natural pauses, repetitions, or fillers such as “...” or “!” — but don’t overdo it. Do not invent new words or distort the original meaning.  \n",
    "Do not start with words like “Oh”, “So”, “Uhm”, or “Huh”.  \n",
    "\n",
    "If the {input_language} input seems incomplete (cut off mid-sentence), output an unfinished {output_language} sentence too, so it can be naturally continued. You don’t need to force a full translation of every fragment if it isn’t complete yet.\n",
    "한글 종결 어미의 특징 : ~~요. ~~니다. ~~어.\n",
    "\n",
    "Continue from existing {output_language} translation.  \n",
    "Do not echo or include the existing translation in the output — return only the newly translated continuation.\n",
    "\n",
    "- If more input is likely to follow, end with `...`.\n",
    "- If the current {input_language} input + context forms a COMPLETE sentence in {output_language}, Do not end with `...`.\n",
    "\n",
    "# Real-Time Translation Tips\n",
    "1. **Avoid Premature Subject Translation**\n",
    "- Korean often omits or ambiguates the subject.\n",
    "- When the subject is unclear, try to infer it from prior context.\n",
    "- If there’s even slight ambiguity, avoid explicitly translating the subject (\"I\", \"we\", \"they\", etc.) and use neutral or impersonal expressions instead.\n",
    "- Example:\n",
    "  - Korean: “마케팅비를 청구해야 한다”\n",
    "  - Preferred: “Marketing costs must also be claimed.”\n",
    "  - Not: “I should claim the marketing costs.”\n",
    "- Example:\n",
    "  - Korean: \"내일 집에\"\n",
    "  - Preferred: \"Tomorrow,\"\n",
    "  - Not: \"Tomorrow at home, I'll \"\n",
    "\n",
    "2. Do not include the verb in the translation if no verb is spoken.\n",
    "- Korean places verbs at the end. Don't translate prematurely if the action is unknown.\n",
    "- Example: “운동장에가서 축구를…”\n",
    "  - Preferred: \"I'll go to the sports field and...\" # Still don't know whether they will play soccer or watch. Just skip the sentence, because there will be more input to come next.\n",
    "  - Not: \"I'll go to the sports field and play soccer...\" # This is not correct, because next input can be \"축구를 봤어.\"\n",
    "- Example: \"오늘 아침에 밥을\"\n",
    "  - Preferred: \"This morning,\" # Still don't know whether they will eat breakfast or not. You dont have to include all words in the input.\n",
    "  - Not: \"I had breakfast this morning.\"\n",
    "\n",
    "-- INPUT --  \n",
    "<previous utterances> {hist}  \n",
    "<speaking {input_language}> : {current_scripted_sentence}  \n",
    "<{output_language}> : {current_translated}  \n",
    "\"\"\"}\n",
    "        ],\n",
    "        temperature=0.1,\n",
    "        user=\"k2e-translator-v1-hojinkhj6051230808\",\n",
    "        prompt_cache_key=\"k2e-translator-v1-hojinkhj6051230808\",\n",
    "        stream=True,\n",
    "        stream_options={\"include_usage\": True},\n",
    "    )\n",
    "\n",
    "    sent = ''\n",
    "    first = 0\n",
    "    st = time.time()\n",
    "\n",
    "    pt = 0\n",
    "    pt_cached = 0\n",
    "    ct = 0\n",
    "\n",
    "    for chunk in response:\n",
    "        if chunk.usage and chunk.usage is not None:\n",
    "            u = chunk.usage;\n",
    "            pt += u.prompt_tokens\n",
    "            pt_cached += u.prompt_tokens_details.cached_tokens\n",
    "            ct += u.completion_tokens\n",
    "        else:\n",
    "            if chunk.choices[0].delta.content != '' and chunk.choices[0].delta.content is not None:\n",
    "                onToken(chunk.choices[0].delta.content)\n",
    "                sent += chunk.choices[0].delta.content\n",
    "\n",
    "    return {\n",
    "        \"text\": sent,\n",
    "        \"prompt_tokens\": pt,\n",
    "        \"prompt_tokens_cached\": pt_cached,\n",
    "        \"completion_tokens\": ct\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecd16390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '...talked with a friend last night.', 'prompt_tokens': 659, 'prompt_tokens_cached': 0, 'completion_tokens': 9}\n",
      "{'text': '...and stayed up late.', 'prompt_tokens': 678, 'prompt_tokens_cached': 0, 'completion_tokens': 6} \n",
      "\n",
      "{'text': '... 같이 시간을 보내는 게 좋아요.', 'prompt_tokens': 659, 'prompt_tokens_cached': 0, 'completion_tokens': 9}\n",
      "{'text': \"... and I think it'll be fun to spend time together.\", 'prompt_tokens': 678, 'prompt_tokens_cached': 0, 'completion_tokens': 12} \n",
      "\n",
      "{'text': 'was thinking about that project...', 'prompt_tokens': 658, 'prompt_tokens_cached': 0, 'completion_tokens': 6}\n",
      "{'text': \"but I actually didn't want to keep working on it.\", 'prompt_tokens': 671, 'prompt_tokens_cached': 0, 'completion_tokens': 11} \n",
      "\n",
      "{'text': '...that person said...', 'prompt_tokens': 659, 'prompt_tokens_cached': 0, 'completion_tokens': 5}\n",
      "{'text': \"...they're planning to change jobs soon.\", 'prompt_tokens': 674, 'prompt_tokens_cached': 0, 'completion_tokens': 9} \n",
      "\n",
      "{'text': '...갈 거예요.', 'prompt_tokens': 662, 'prompt_tokens_cached': 0, 'completion_tokens': 6}\n",
      "{'text': '...to take the bus and go to work tomorrow morning.', 'prompt_tokens': 674, 'prompt_tokens_cached': 0, 'completion_tokens': 12} \n",
      "\n",
      "{'text': '...친구들이랑 같이 노는 걸 좋아해요.', 'prompt_tokens': 659, 'prompt_tokens_cached': 0, 'completion_tokens': 13}\n",
      "{'text': '...그래서 종종 도서관에서 공부하거나 책 읽는 걸 좋아해요.', 'prompt_tokens': 680, 'prompt_tokens_cached': 0, 'completion_tokens': 19} \n",
      "\n",
      "{'text': \"...really fast and lightweight, so I think it'll be pretty good for working on the go.\", 'prompt_tokens': 662, 'prompt_tokens_cached': 0, 'completion_tokens': 19}\n",
      "{'text': 'It lasts a long time on a single charge.', 'prompt_tokens': 688, 'prompt_tokens_cached': 0, 'completion_tokens': 10} \n",
      "\n",
      "{'text': '...the stuff that happened at work today.', 'prompt_tokens': 661, 'prompt_tokens_cached': 0, 'completion_tokens': 9}\n",
      "{'text': 'It was a bit shocking.', 'prompt_tokens': 678, 'prompt_tokens_cached': 0, 'completion_tokens': 6} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from llm.openai import translate\n",
    "import time\n",
    "\n",
    "examples = [\n",
    "    ['어제 밤에 친구랑', '늦게까지 얘기했어요.'],\n",
    "    ['주말에는 가족이랑', '바다에 놀러갈 거예요.'],\n",
    "    ['저는 사실 그 프로젝트를', '계속 하고 싶지 않았어요.'],\n",
    "    ['그 사람이 말하길.', '곧 이직할 거라고 했어요.'],\n",
    "\n",
    "    # 명확히 불완전한 케이스\n",
    "    ['내일 아침에 버스 타고', '출근하려고요.'],\n",
    "    ['저는 항상 학교 끝나고', '도서관에 갔어요.'],\n",
    "    ['이번에 새로 산 노트북은', '배터리가 오래 가요.'],\n",
    "    ['오늘 회사에서 있었던 일은.', '조금 충격적이었어요.'],\n",
    "]\n",
    "\n",
    "for ex in examples:\n",
    "    output1 = translate([], ex[0], \"\", lambda x: None)\n",
    "    output2 = translate([], f\"{ex[0]} {ex[1]}\", output1['text'], lambda x: None)\n",
    "\n",
    "    print(output1)\n",
    "    print(output2, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df57f2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 지금 계속 한글로 말하는걸 영어로 번역하고 있어.\n",
    "# <previous utterances>는 현재 문장 이전에 이야기하던 문장이야. 번역을 위한 맥락 파악에 사용할 수 있어.\n",
    "# <speaking english>은 번역해야하는 현재 발화야.\n",
    "\n",
    "# 말을 하는걸 script로 만든 input이기 때문에, 발음 문제로 인해서 텍스트가 잘못 들어왔을 수 있어. 그걸 감안해서 번역해줘.\n",
    "\n",
    "# 출력 english를 일반 글 문장보다는 실제로 사람이 말하는 것 같은 구어체로 적어줘. 예를 들어, 같은 단어를 두번 쓰거나 뭐 ...을 쓰거나 느낌표 이런 것들 있잖아?\n",
    "# Translate into casual spoken English. 근데 너무 심하게 하진 말고, 없는 말을 만들거나 들어온 input을 왜곡하면 안돼.\n",
    "# Do not start with word like Oh, So, Uhm, Huh, etc.\n",
    "\n",
    "# 혹시 한글 문장이 아직 종결되지 않았는데 중간에 들어온 것 같으면, 출력 영어도 종결되지 않고 뒤에 이어질 수 있는 문장으로 뱉어줘.\n",
    "# 뒤에 어떤 말이 들어올지 모르니까 만약 문장이 종결되지 않았다고 판단되면, 뒤에 어떤 문장이 들어오던 현재 출력하는 문장을 이어서 완성할 수 있게 해야해.\n",
    "# 그래서 꼭 지금 한글 input을 전부 번역할 필요는 없어.\n",
    "\n",
    "# 현재까지 번역된 문장이 있으면, 그 문장을 이어서 번역해줘. 먼저 들어온 번역 문장이 잘못 되었을 수도 있어. 그래도 알아서 잘 구어체로.\n",
    "# 추가 번역되어야하는 문장만 출력해줘.\n",
    "\n",
    "# 그리고 만약 뒤에 어떤 다른 문장이 들어오던 현재의 speaking korean을 전부 <english>에 포함시켜서 번역이 완료되었다면, 마지막에 <END>를 붙여줘.\n",
    "# 뒤에 추가로 번역이 필요하면 ...을 마지막에 붙여줘.\n",
    "\n",
    "# -- INPUT --\n",
    "# <previous utterances>{hist}\n",
    "# <speaking korean> : {current_scripted_sentence}\n",
    "# <english> : {current_translated}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a931d70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khj6051/chatter/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING:root:Failed import k2 with error No module named 'k2'. Swoosh functions will fallback to PyTorch implementation, leading to slower speed and higher memory consumption.\n"
     ]
    }
   ],
   "source": [
    "from tts.zipvoice_infer import load_infer_context\n",
    "ctx = load_infer_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2057a7b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m fd \u001b[38;5;241m=\u001b[39m ctx[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfm_decoder\n\u001b[0;32m----> 5\u001b[0m trainable_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mparameters() \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrainable parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainable_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "fd = ctx['model'].fm_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93dacf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 118494140\n"
     ]
    }
   ],
   "source": [
    "trainable_params = sum(p.numel() for p in fd.parameters() if p.requires_grad)\n",
    "print(f\"Trainable parameters: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca674e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
